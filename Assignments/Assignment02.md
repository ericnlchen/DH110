# **Assignment 2: Pilot Usability Testing**
Eric Chen | DH110 | Spring 2023

## **Introduction:**
In this assignment, I conducted a pilot usability test for the Waffle app. Waffle is a shared journaling app that lets friends and family share stories and thoughts with one another. This app is particularly relevant to my project, because I hope to design a shared journaling app similar to Waffle but more optimized for family use across multiple generations. Waffle provides basic functionalities like sharing journals, creating entries with text and images, and saving drafts to come back to them later.  

A **usable** software is defined as one which enables users to accomplish certain goals in an effective, efficient, and satisfying manner. The purpose of a **usability test** is to determine a software interface's usability by directly observing a user as they attempt to accomplish certain goals. The test is usually conducted with a group of users in a dedicated lab or portable test setting. Sessions are recorded and analyzed to identify potential areas for improvement.  

For this assignment, I am conducting a **pilot** test, which means that its purpose is to test my script, questionnaire, and equipment before engaging in an actual test.  

Since this is a pilot test, I have one participant. My participant tested the current version of the Waffle app on their Apple iPhone while filling out survey results on their personal laptop, which was also connected to me on a Zoom call. The participant's laptop camera captured their face throughout the duration of the test. The iPhone screen recording tool captured the participant's interactions with their phone.  

During assignment 1, I conducted a heuristic evaluation where I discovered my own usability issues by interacting with the Waffle app and analyzing it within the framework of Nielsen's 10 heuristics. Based on this evaluation, the most severe issue I discovered was the unintuitive *drafts* function. Therefore, I will ask my user to try the drafts functionality as one of my tasks. For the other tasks, I wanted to check the general usability of the core functionalities of the app, so I asked my user to create and share a journal and to post an entry.  

## **Methodology:**
The participant was recruited by directly asking them in-person, and they volunteered their time with no compensation. The session lasted for just over 30 minutes. During the session, I acted as the moderator. First, I explained the test session and asked the participant for their informed consent. Then, I asked some pre-test questions before the participant interacted with the Waffle app. Next, I asked the participant to complete 3 in-app tasks. When they completed all 3 tasks, I asked them to fill out 7-point Likert scale questions aimed at evaluating:
- How easy the tasks were
- How long the tasks took
- How likely the user was to do those tasks  

Finally, the participant was provided with more general statments about the website which they could agree or disagree with on a 7-point Likert scale. The qualities measured included:
- How easy it was to learn
- Simplicity/complexity
- Degree of integration between various functions
- Degree of confidence using the app  

Please see the **Test Materials** section below for the full list of questions.

## **Test Materials:**
The test questionnaire can be found [here.](https://forms.gle/hW4whp9HpB8r29i7A)

## **Video of Session:**
[![My video](http://img.youtube.com/vi/p_ZU-9lD03c/0.jpg)](https://www.youtube.com/watch?v=p_ZU-9lD03c "My video")

## **Reflection:**
In conducting this pilot test, I learned that my first two tasks may have been too trivial. My participant completed these tasks very easily and quickly. This is still a useful finding, since it suggests that the usability for those parts of the interface is good, but it may have been better to challenge the user more in order to discover more issues.  

My third task in the test went quite well, since the user provided useful information by struggling to complete the task and then finding a solution which I didn't even know about. Another aspect that went well was the users ability to speak out loud throughout the whole test--this provides lots of detailed information which could help someone better tailor the app to the users' needs.  

Going forward, I will extend my first two tasks so that they have a higher likelihood of exposing new usability issues. For example, maybe I can ask users to try posting an entry, a question, and an event (3 types of writing you can post in your journal). I could also ask users to try deleting an entry, or to enable the "question of the day" functionality. All of these extensions could make the tasks more challenging and enable me to extract better data.
